{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52cd2a0e",
   "metadata": {},
   "source": [
    "# Dataset Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb588ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k006-004-v7.hpcfund\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db28c96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work1/lgarcia/renneruan/cached_data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "WORK_DIR = os.getenv('WORK')\n",
    "\n",
    "DATA_FOLDER = os.path.join(WORK_DIR, \"data\")\n",
    "\n",
    "CACHED_DATA_FOLDER = os.path.join(WORK_DIR, \"cached_data\")\n",
    "\n",
    "# Salvamos o path do Cache par ao HuggingFace\n",
    "os.environ['HF_HOME'] = CACHED_DATA_FOLDER\n",
    "\n",
    "CACHED_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d344d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.48.1\n"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "from datasets import load_dataset, concatenate_datasets, load_from_disk\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from bs4 import BeautifulSoup, MarkupResemblesLocatorWarning\n",
    "from ftfy import fix_text\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
    "\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0b6db8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work1/lgarcia/renneruan\n"
     ]
    }
   ],
   "source": [
    "os.chdir(WORK_DIR)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066bf645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-env  cached_data  data  notebooks\trequirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75702d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "drwxr-xr-x 1 renneruan lgarcia    0 Sep 23 09:58 \u001b[0m\u001b[01;34mbert-env\u001b[0m/\n",
      "drwxr-xr-x 1 renneruan lgarcia    0 Sep 23 22:06 \u001b[01;34mcached_data\u001b[0m/\n",
      "drwxr-xr-x 1 renneruan lgarcia    0 Sep 23 22:42 \u001b[01;34mdata\u001b[0m/\n",
      "drwxr-xr-x 1 renneruan lgarcia    0 Sep 23 20:26 \u001b[01;34mnotebooks\u001b[0m/\n",
      "-rw-r--r-- 1 renneruan lgarcia 2665 Sep 23 09:58 requirements.txt\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9c596",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Wikipedia Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57bb9505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1112246\n",
      "}) \n",
      "\n",
      "Astronomia é uma ciência natural que estuda corpos celestes (como estrelas, planetas, cometas, nebul\n"
     ]
    }
   ],
   "source": [
    "wikipedia = load_dataset(\n",
    "    \"wikimedia/wikipedia\", \n",
    "    \"20231101.pt\", \n",
    "    split=\"train\", \n",
    "    num_proc=cpu_count(),\n",
    "    cache_dir=CACHED_DATA_FOLDER\n",
    ")\n",
    "\n",
    "# Mantemos apenas coluna de Texto\n",
    "wikipedia = wikipedia.remove_columns([col for col in wikipedia.column_names if col != \"text\"])  \n",
    "\n",
    "print(wikipedia, '\\n')\n",
    "print(wikipedia[0][\"text\"][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602bd2a8",
   "metadata": {},
   "source": [
    "### BrWac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfc1d938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5016734659d54d44b7d0e78465b2b04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeed8b324df048edb9db60989b0ddcb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2760046bd8441eb836e00e5c36c90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3530796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ee7ebdae414ebba85b198c88a194a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1112246\n",
      "}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "brwac = load_dataset(\n",
    "    \"dominguesm/brwac\", \n",
    "    # data_dir=\"dataset-brwac\",\n",
    "    split=\"train\", \n",
    "    num_proc=cpu_count(),\n",
    "    cache_dir=CACHED_DATA_FOLDER,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "brwac = brwac.remove_columns([col for col in brwac.column_names if col != \"text\"])\n",
    "\n",
    "print(wikipedia, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5af93dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Conteúdo recente'],\n",
       " ['ESPUMA MARROM CHAMADA \"NINGUÉM MERECE\"'],\n",
       " ['31 de Agosto de 2015, 7:07 , por paulo soavinski - | No one following this article yet.'],\n",
       " ['Visualizado 202 vezes'],\n",
       " ['JORNAL ELETRÔNICO DA ILHA DO MEL'],\n",
       " ['Uma espuma marrom escuro tem aparecido com frequência na Praia de Fora.',\n",
       "  'Na faixa de areia ela aparece disseminada e não chama muito a atenção.',\n",
       "  'No Buraco do Aipo, com muitas pedras, ela aparece concentrada.',\n",
       "  'É fácil saber que esta espuma estranha está lá, quando venta.',\n",
       "  'Pequenos algodões de espuma começam a flutuar no espaço, pertinho da Praia do Saquinho.',\n",
       "  'Quem pode ajudar na coleta deste material, envio a laboratório renomado e pagamento de análises, favor entrar em contato com o site.']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brwac[0][\"text\"][\"paragraphs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96e3c427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteúdo recente\n",
      "ESPUMA MARROM CHAMADA \"NINGUÉM MERECE\"\n",
      "31 de Agosto de 2015, 7:07 , por paulo soavinski - | No one following this article yet.\n",
      "Visualizado 202 vezes\n",
      "JORNAL ELETRÔNICO DA ILHA DO MEL\n",
      "Uma espuma marrom escuro tem aparecido com frequência na Praia de Fora.\n",
      "Na faixa de areia ela aparece disseminada e não chama muito a atenção.\n",
      "No Buraco do Aipo, com muitas pedras, ela aparece concentrada.\n",
      "É fácil saber que esta espuma estranha está lá, quando venta.\n",
      "Pequenos algodões de espuma começam a flutuar no espaço, pertinho da Praia do Saquinho.\n",
      "Quem pode ajudar na coleta deste material, envio a laboratório renomado e pagamento de análises, favor entrar em contato com o site.\n"
     ]
    }
   ],
   "source": [
    "for paragraph in brwac[0][\"text\"][\"paragraphs\"]:\n",
    "    for doc in paragraph:\n",
    "        soup = BeautifulSoup(doc, 'html.parser')\n",
    "        print( fix_text(soup.get_text())  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9247687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955501b0cfe74e86b7b2fba4a6c43c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/3530796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n",
      "/tmp/ipykernel_389183/1676243496.py:8: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  soup = BeautifulSoup(doc, 'html.parser')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 3530796\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def paragraph2doc(example):\n",
    "    list_doc = []\n",
    "\n",
    "    for row in example[\"text\"]:\n",
    "        str_doc = \"\"\n",
    "        for paragraph in row[\"paragraphs\"]:\n",
    "            for doc in paragraph:\n",
    "                soup = BeautifulSoup(doc, 'html.parser') \n",
    "\n",
    "                str_doc += fix_text(soup.get_text()) + '\\n'\n",
    "\n",
    "        list_doc.append(str_doc)\n",
    "    return {\"text\" : list_doc}\n",
    "\n",
    "preprocessed_brwac = brwac.map(\n",
    "    paragraph2doc,\n",
    "    batched = True,\n",
    "    remove_columns=[\"text\"],\n",
    "    num_proc = cpu_count(),\n",
    ")\n",
    "\n",
    "# preprocessed_brwac = preprocessed_brwac.rename_column(\"paragraphs\", \"text\")\n",
    "preprocessed_brwac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4b666cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = concatenate_datasets([wikipedia, preprocessed_brwac])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70fafed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 4643042\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b1650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_save_path = os.path.join(DATA_FOLDER, 'concatenated_raw_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6084f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd61c7b5f7904c2cac763a988fe8985d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/41 shards):   0%|          | 0/4643042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets.save_to_disk(concatenated_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e0fa57",
   "metadata": {},
   "source": [
    "### C4 (Muito Grande)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c4 = load_dataset(  \n",
    "#     \"allenai/c4\", \n",
    "#     \"pt\", \n",
    "#     split=\"train[:1%]\", \n",
    "#     cache_dir=CACHED_DATA_FOLDER,\n",
    "#     num_proc=cpu_count()\n",
    "# )\n",
    "\n",
    "# c4 = c4.remove_columns([col for col in c4.column_names if col != \"text\"])\n",
    "\n",
    "# print(c4, '\\n')\n",
    "# print(c4[0][\"text\"][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0346065",
   "metadata": {},
   "source": [
    "### Oscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oscar = load_dataset(\n",
    "#     'oscar-corpus/community-oscar', \n",
    "#     data_files='data/2024-38/pt_meta/*.jsonl.zst', \n",
    "#     split='train',\n",
    "#     streaming=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39fe51",
   "metadata": {},
   "source": [
    "### C4 Legal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02fc055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mc4legal = load_dataset(\n",
    "#     \"joelito/mc4_legal\", \n",
    "#     \"pt\", \n",
    "#     split='train', \n",
    "#     trust_remote_code=True, \n",
    "#     num_proc=cpu_count())\n",
    "\n",
    "# mc4legal = mc4legal.remove_columns([col for col in mc4legal.column_names if col != \"text\"])  # only keep the 'text' column\n",
    "\n",
    "# print(mc4legal, '\\n')\n",
    "\n",
    "# print(mc4legal[\"text\"][0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c581ae4",
   "metadata": {},
   "source": [
    "### Multi Legal Pile (Muito Grande)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f350a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # multilegal has 17M, which is too much, use only 5% (0.86M)\n",
    "# multilegal = load_dataset('joelniklaus/Multi_Legal_Pile', \n",
    "#                           \"pt_caselaw\", \n",
    "#                           split='train[:5%]', \n",
    "#                           trust_remote_code=True, \n",
    "#                           num_proc=cpu_count()\n",
    "#                           )\n",
    "\n",
    "# multilegal = multilegal.remove_columns([col for col in multilegal.column_names if col != \"text\"])  # only keep the 'text' column\n",
    "\n",
    "# print(multilegal, '\\n')\n",
    "\n",
    "# print(multilegal[\"text\"][0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dda5e0",
   "metadata": {},
   "source": [
    "### LeNER-BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb8aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/peluz/lener-br/archive/refs/heads/master.zip\n",
    "\n",
    "!unzip master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate files and convert the documents to a dataset object\n",
    "\n",
    "raw_directory_path = \"lener-br-master/leNER-Br/raw_text\"\n",
    "raw_lener = { \"text\" : [] }\n",
    "\n",
    "for file in os.listdir(raw_directory_path):\n",
    "    filename = os.fsdecode(file)\n",
    "\n",
    "    if filename.endswith(\".txt\"):\n",
    "\n",
    "        with open(f\"{raw_directory_path}/{filename}\", 'r') as f:\n",
    "            raw_lener[\"text\"].append( f.read() )\n",
    "\n",
    "lener = Dataset.from_dict(raw_lener)\n",
    "\n",
    "print(lener, '\\n')\n",
    "\n",
    "print(lener[\"text\"][0][:1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-env",
   "language": "python",
   "name": "bert-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
