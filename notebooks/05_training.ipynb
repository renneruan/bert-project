{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1571138",
   "metadata": {},
   "source": [
    "# Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fff3434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k005-009.hpcfund\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5712c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================= ROCm System Management Interface =========================================\n",
      "=================================================== Concise Info ===================================================\n",
      "Device  Node  IDs              Temp    Power  Partitions          SCLK    MCLK     Fan  Perf  PwrCap  VRAM%  GPU%  \n",
      "\u001b[3m              (DID,     GUID)  (Edge)  (Avg)  (Mem, Compute, ID)                                                   \u001b[0m\n",
      "====================================================================================================================\n",
      "0       5     0x740f,   36740  36.0째C  42.0W  N/A, N/A, 0         800Mhz  1600Mhz  0%   auto  300.0W  0%     0%    \n",
      "1       4     0x740f,   22429  41.0째C  43.0W  N/A, N/A, 0         800Mhz  1600Mhz  0%   auto  300.0W  0%     0%    \n",
      "2       3     0x740f,   32693  39.0째C  43.0W  N/A, N/A, 0         800Mhz  1600Mhz  0%   auto  300.0W  0%     0%    \n",
      "3       2     0x740f,   42924  42.0째C  40.0W  N/A, N/A, 0         800Mhz  1600Mhz  0%   auto  300.0W  0%     0%    \n",
      "====================================================================================================================\n",
      "=============================================== End of ROCm SMI Log ================================================\n"
     ]
    }
   ],
   "source": [
    "!rocm-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553327ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work1/lgarcia/renneruan/cached_data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "WORK_DIR = os.getenv('WORK')\n",
    "\n",
    "DATA_FOLDER = os.path.join(WORK_DIR, \"data\")\n",
    "\n",
    "CACHED_DATA_FOLDER = os.path.join(WORK_DIR, \"cached_data\")\n",
    "\n",
    "# Salvamos o path do Cache par ao HuggingFace\n",
    "os.environ['HF_HOME'] = CACHED_DATA_FOLDER\n",
    "os.environ['TRITON_HIP_LLD_PATH'] = '/opt/rocm-6.4.1/lib/llvm/bin/ld.lld'\n",
    "\n",
    "\n",
    "CACHED_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfe9feeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work1/lgarcia/renneruan\n"
     ]
    }
   ],
   "source": [
    "os.chdir(WORK_DIR)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619ecd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5187593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0.dev20250825+rocm6.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "319e4e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------------------\n",
      "accelerate                1.10.1\n",
      "aiohappyeyeballs          2.6.1\n",
      "aiohttp                   3.12.15\n",
      "aiosignal                 1.4.0\n",
      "anyio                     4.11.0\n",
      "argon2-cffi               25.1.0\n",
      "argon2-cffi-bindings      25.1.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 3.0.0\n",
      "async-lru                 2.0.5\n",
      "async-timeout             5.0.1\n",
      "attrs                     25.3.0\n",
      "babel                     2.17.0\n",
      "beautifulsoup4            4.13.5\n",
      "bleach                    6.2.0\n",
      "certifi                   2025.8.3\n",
      "cffi                      2.0.0\n",
      "charset-normalizer        3.4.3\n",
      "click                     8.1.8\n",
      "comm                      0.2.3\n",
      "contourpy                 1.3.0\n",
      "cycler                    0.12.1\n",
      "datasets                  4.1.1\n",
      "debugpy                   1.8.17\n",
      "decorator                 5.2.1\n",
      "defusedxml                0.7.1\n",
      "dill                      0.4.0\n",
      "einops                    0.8.1\n",
      "exceptiongroup            1.3.0\n",
      "executing                 2.2.1\n",
      "fastjsonschema            2.21.2\n",
      "filelock                  3.19.1\n",
      "flash_attn                2.8.3\n",
      "fonttools                 4.60.0\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.7.0\n",
      "fsspec                    2025.9.0\n",
      "ftfy                      6.3.1\n",
      "h11                       0.16.0\n",
      "hf-xet                    1.1.10\n",
      "httpcore                  1.0.9\n",
      "httpx                     0.28.1\n",
      "huggingface-hub           0.35.1\n",
      "idna                      3.10\n",
      "importlib_metadata        7.1.0\n",
      "importlib_resources       6.5.2\n",
      "ipykernel                 6.30.1\n",
      "ipython                   8.18.1\n",
      "ipywidgets                8.1.7\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.6\n",
      "joblib                    1.5.2\n",
      "json5                     0.12.1\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.25.1\n",
      "jsonschema-specifications 2025.9.1\n",
      "jupyter                   1.1.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.8.1\n",
      "jupyter-events            0.12.0\n",
      "jupyter-lsp               2.3.0\n",
      "jupyter_server            2.17.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.4.9\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.15\n",
      "kiwisolver                1.4.7\n",
      "lark                      1.3.0\n",
      "MarkupSafe                3.0.2\n",
      "matplotlib                3.9.4\n",
      "matplotlib-inline         0.1.7\n",
      "mistune                   3.1.4\n",
      "mpmath                    1.3.0\n",
      "multidict                 6.6.4\n",
      "multiprocess              0.70.16\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.6\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.2.1\n",
      "ninja                     1.13.0\n",
      "nltk                      3.9.1\n",
      "notebook                  7.4.6\n",
      "notebook_shim             0.2.4\n",
      "numpy                     1.26.4\n",
      "overrides                 7.7.0\n",
      "packaging                 25.0\n",
      "pandas                    2.3.2\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.5\n",
      "pexpect                   4.9.0\n",
      "pillow                    11.3.0\n",
      "pip                       25.2\n",
      "platformdirs              4.4.0\n",
      "prometheus_client         0.23.1\n",
      "prompt_toolkit            3.0.52\n",
      "propcache                 0.3.2\n",
      "psutil                    7.1.0\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "pyarrow                   21.0.0\n",
      "pycparser                 2.23\n",
      "Pygments                  2.19.2\n",
      "pyparsing                 3.2.5\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        3.3.0\n",
      "pytorch-triton-rocm       3.4.0+gitf7888497\n",
      "pytz                      2025.2\n",
      "PyYAML                    6.0.3\n",
      "pyzmq                     27.1.0\n",
      "referencing               0.36.2\n",
      "regex                     2025.9.18\n",
      "requests                  2.32.5\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rfc3987-syntax            1.1.0\n",
      "rpds-py                   0.27.1\n",
      "safetensors               0.6.2\n",
      "Send2Trash                1.8.3\n",
      "setuptools                80.9.0\n",
      "six                       1.17.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.8\n",
      "stack-data                0.6.3\n",
      "sympy                     1.14.0\n",
      "terminado                 0.18.1\n",
      "tinycss2                  1.4.0\n",
      "tokenizers                0.22.1\n",
      "tomli                     2.2.1\n",
      "torch                     2.9.0.dev20250825+rocm6.4\n",
      "torchaudio                2.8.0.dev20250825+rocm6.4\n",
      "torchvision               0.24.0.dev20250825+rocm6.4\n",
      "tornado                   6.5.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "transformers              4.56.2\n",
      "types-python-dateutil     2.9.0.20250822\n",
      "typing_extensions         4.15.0\n",
      "tzdata                    2025.2\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.5.0\n",
      "wcwidth                   0.2.14\n",
      "webcolors                 24.11.1\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "wheel                     0.45.1\n",
      "widgetsnbextension        4.0.14\n",
      "xxhash                    3.5.0\n",
      "yarl                      1.20.1\n",
      "zipp                      3.19.2\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b0221e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1947fdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "from transformers import ModernBertConfig\n",
    "from transformers import ModernBertForMaskedLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import get_wsd_schedule\n",
    "from torch.optim import AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6849477d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0.dev20250825+rocm6.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acc3697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 32_768\n",
    "context_size = 512\n",
    "tokenizer_name = f\"tokenizers/custom/{vocabulary_size:_}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7fff7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3ba62ab0dd4f868776e22bb9a62a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7e6d8e3a294581be831f2bc2e5859e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': List(Value('int32')), 'token_type_ids': List(Value('int8')), 'attention_mask': List(Value('int8')), 'special_tokens_mask': List(Value('int8'))} \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "        num_rows: 56726693\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "        num_rows: 6302966\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets_name = os.path.join(DATA_FOLDER, f\"tokenized-for-training/custom/vocab_size:{vocabulary_size:_}/context_size:{context_size}\")\n",
    "\n",
    "tokenized_datasets = load_from_disk(tokenized_datasets_name)\n",
    "\n",
    "print(tokenized_datasets[\"train\"].features, '\\n')\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7225078b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "    num_rows: 56726693\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = tokenized_datasets[\"train\"] #.select([i for i in range( int(1 * len(tokenized_datasets[\"train\"])) )])\n",
    "\n",
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b93aa025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "    num_rows: 6302966\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataset = tokenized_datasets[\"test\"] #.select([i for i in range( int(1 * len(tokenized_datasets[\"test\"])) )])\n",
    "\n",
    "evaluation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73030a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "     num_rows: 56726693\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "     num_rows: 6302966\n",
       " }))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.set_format(type=\"pt\", columns=['input_ids', 'attention_mask', 'special_tokens_mask'])\n",
    "\n",
    "evaluation_dataset.set_format(type=\"pt\", columns=['input_ids', 'attention_mask', 'special_tokens_mask'])\n",
    "\n",
    "training_dataset, evaluation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58bc19a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"Modern/{4.6}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "396fdf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModernBertConfig {\n",
       "  \"architectures\": [\n",
       "    \"ModernBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 50281,\n",
       "  \"classifier_activation\": \"gelu\",\n",
       "  \"classifier_bias\": false,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"classifier_pooling\": \"mean\",\n",
       "  \"cls_token_id\": 50281,\n",
       "  \"decoder_bias\": true,\n",
       "  \"deterministic_flash_attn\": false,\n",
       "  \"dtype\": \"float16\",\n",
       "  \"embedding_dropout\": 0.0,\n",
       "  \"eos_token_id\": 50282,\n",
       "  \"global_attn_every_n_layers\": 3,\n",
       "  \"global_rope_theta\": 160000.0,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_activation\": \"gelu\",\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_cutoff_factor\": 2.0,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 1152,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"local_attention\": 128,\n",
       "  \"local_rope_theta\": 10000.0,\n",
       "  \"max_position_embeddings\": 8192,\n",
       "  \"mlp_bias\": false,\n",
       "  \"mlp_dropout\": 0.0,\n",
       "  \"model_type\": \"modernbert\",\n",
       "  \"norm_bias\": false,\n",
       "  \"norm_eps\": 1e-05,\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 22,\n",
       "  \"pad_token_id\": 50283,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"repad_logits_with_grad\": false,\n",
       "  \"sep_token_id\": 50282,\n",
       "  \"sparse_pred_ignore_index\": -100,\n",
       "  \"sparse_prediction\": false,\n",
       "  \"transformers_version\": \"4.56.2\",\n",
       "  \"vocab_size\": 50368\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ModernBertConfig.from_pretrained(\n",
    "    \"answerdotai/ModernBERT-base\",\n",
    "      reference_compile=False,\n",
    "      attn_implementation=\"flash_attention_2\",\n",
    "    dtype=torch.float16)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb8842e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModernBertConfig {\n",
       "  \"architectures\": [\n",
       "    \"ModernBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 2,\n",
       "  \"classifier_activation\": \"gelu\",\n",
       "  \"classifier_bias\": false,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"classifier_pooling\": \"mean\",\n",
       "  \"cls_token_id\": 2,\n",
       "  \"decoder_bias\": true,\n",
       "  \"deterministic_flash_attn\": false,\n",
       "  \"dtype\": \"float16\",\n",
       "  \"embedding_dropout\": 0.0,\n",
       "  \"eos_token_id\": 3,\n",
       "  \"global_attn_every_n_layers\": 3,\n",
       "  \"global_rope_theta\": 160000.0,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_activation\": \"gelu\",\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_cutoff_factor\": 2.0,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 1152,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"local_attention\": 128,\n",
       "  \"local_rope_theta\": 10000.0,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"mlp_bias\": false,\n",
       "  \"mlp_dropout\": 0.0,\n",
       "  \"model_type\": \"modernbert\",\n",
       "  \"norm_bias\": false,\n",
       "  \"norm_eps\": 1e-05,\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 22,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"repad_logits_with_grad\": false,\n",
       "  \"sep_token_id\": 3,\n",
       "  \"sparse_pred_ignore_index\": -100,\n",
       "  \"sparse_prediction\": false,\n",
       "  \"transformers_version\": \"4.56.2\",\n",
       "  \"vocab_size\": 32768\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diminish the specs\n",
    "\n",
    "# {bert-small} with max_position_embedding = 128\n",
    "\n",
    "config.vocab_size = vocabulary_size\n",
    "config.max_position_embeddings = 512\n",
    "config.local_attention = 128\n",
    "config.pad_token_id = 0\n",
    "config.bos_token_id = 2\n",
    "config.cls_token_id = 2\n",
    "config.eos_token_id = 3\n",
    "config.sep_token_id = 3\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94c10e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.dtype = torch.float16\n",
    "\n",
    "# Initialize model\n",
    "model = ModernBertForMaskedLM(config=config)\n",
    "\n",
    "# Convert all parameters to float16 (safety)\n",
    "model = model.half()\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d5b1408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModernBertForMaskedLM(\n",
       "  (model): ModernBertModel(\n",
       "    (embeddings): ModernBertEmbeddings(\n",
       "      (tok_embeddings): Embedding(32768, 768, padding_idx=0)\n",
       "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): ModernBertEncoderLayer(\n",
       "        (attn_norm): Identity()\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1-2): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (4-5): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (6): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (7-8): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (9): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (10-11): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (12): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (13-14): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (15): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (16-17): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (18): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (19-20): 2 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=10000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (21): ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertUnpaddedRotaryEmbedding(dim=64, base=160000.0, scale_base=None)\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (head): ModernBertPredictionHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=False)\n",
       "    (act): GELUActivation()\n",
       "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Linear(in_features=768, out_features=32768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a30d33db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c5b0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model architecture and configurations to facilitate loading afterwards\n",
    "\n",
    "model.save_pretrained(f\"models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "333f5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, \n",
    "                                          local_files_only=True, \n",
    "                                          cache_dir = CACHED_DATA_FOLDER\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04cc9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask 30% of the tokens\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm = True,\n",
    "    mlm_probability=0.3\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a41994",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = 500_000\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'training/{model_name}',\n",
    "    overwrite_output_dir=True,\n",
    "    \n",
    "    # num_train_epochs=1,                     # number of training epochs\n",
    "    max_steps=total_steps,\n",
    "    # max_steps=100,\n",
    "\n",
    "    gradient_accumulation_steps = 1,\n",
    "    num_workers=64,\n",
    "    # eval_accumulation_steps = 1,\n",
    "\n",
    "    per_device_train_batch_size=256,          # batch size for training\n",
    "    # per_device_eval_batch_size=32,           # batch size for evaluation\n",
    "\n",
    "    \n",
    "    logging_strategy=\"steps\",\n",
    "    logging_first_step=True, # output the initial loss\n",
    "    logging_steps=1_000,\n",
    "    logging_dir=f\"training-logs/{model_name}\",\n",
    "    # report_to=[\"tensorboard\"],\n",
    "\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1_000,                      # Save checkpoints every 100 steps\n",
    "    save_total_limit=5,                  # Limit the total number of saved checkpoints\n",
    "\n",
    "    fp16=True,                            # Enable mixed precision for faster training\n",
    "\n",
    "    # learning_rate=8e-4,\n",
    "    # weight_decay=1e-2,\n",
    "    # adam_beta1=0.9,\n",
    "    # adam_beta2=0.999,\n",
    "    # adam_epsilon=1e-06,\n",
    "    # lr_scheduler_type=\n",
    ")\n",
    "\n",
    "# # Create default optimizer\n",
    "# optimizer = AdamW(\n",
    "#     model.parameters(),\n",
    "#     lr = 8e-4,\n",
    "#     weight_decay=1e-2,\n",
    "#     betas = (0.9, 0.999),\n",
    "# )\n",
    "\n",
    "# scheduler = get_wsd_schedule(\n",
    "#     AdamW,                  # Your optimizer\n",
    "#     num_warmup_steps=total_steps * 0.1,   # Number of warmup steps\n",
    "#     num_decay_steps=total_steps * 0.1,   # Number of decay steps\n",
    "#     # num_training_steps=total_steps,  # Total number of training steps\n",
    "#     num_stable_steps=total_steps * 0.8,   # Number of stable steps\n",
    "#     #warmup_type=\"linear\",   # Warmup type\n",
    "#     #decay_type=\"1-sqrt\",    # Decay type\n",
    "#     min_lr_ratio=0.0,       # Minimum learning rate ratio\n",
    "#     # num_cycles=0.5,         # Number of cosine cycles\n",
    "# )\n",
    "\n",
    "    # lr_scheduler_type=\"warmup_stable_decay\",\n",
    "    # lr_scheduler_kwargs = {\n",
    "    #     #\"optimizer\": \"AdamW\",\n",
    "    #     #\"num_warmup_steps\": 25,l\n",
    "    #     \"num_decay_steps\": 25,\n",
    "    #     #\"num_training_steps\": 1000,\n",
    "    #     \"num_stable_steps\": 950,\n",
    "    #     # \"warmup_type\": \"linear\",\n",
    "    #     #\"decay_type\": \"1-sqrt\",\n",
    "    #     #\"min_lr_ratio\": 0,\n",
    "    # },\n",
    "    # # warmup_steps=25,\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                        # Model to train\n",
    "    args=training_args,                 # Training arguments\n",
    "    train_dataset=training_dataset,     # Training dataset\n",
    "    # eval_dataset=evaluation_dataset,    # Evaluation dataset\n",
    "    data_collator=data_collator,\n",
    "    # optimizers=(optimizer, scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "192341c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "331a3328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.cuda' from '/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/cuda/__init__.py'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d810349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6765bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export TRITON_HIP_LLD_PATH=\"/opt/rocm-6.2.1/lib/llvm/bin/ld.lld\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c8e7b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIP version: 6.4.43483-a187df25c\n",
      "AMD clang version 19.0.0git (https://github.com/RadeonOpenCompute/llvm-project roc-6.4.1 25184 c87081df219c42dc27c5b6d86c0525bc7d01f727)\n",
      "Target: x86_64-unknown-linux-gnu\n",
      "Thread model: posix\n",
      "InstalledDir: /opt/rocm-6.4.1/lib/llvm/bin\n",
      "Configuration file: /opt/rocm-6.4.1/lib/llvm/bin/clang++.cfg\n"
     ]
    }
   ],
   "source": [
    "!hipcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f7e9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade fastai\n",
    "# # ou, se for accelerate:\n",
    "# !pip install --upgrade accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "358d824d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de1f82ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Default tensor device: cpu\n",
      "Current GPU: 0\n",
      "GPU name: AMD Instinct MI210\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Is any GPU available?\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Device of a new tensor\n",
    "x = torch.randn(1)\n",
    "print(\"Default tensor device:\", x.device)\n",
    "\n",
    "# Optional: check which GPU (if any) would be used\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current GPU:\", torch.cuda.current_device())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ea5c4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(p.is_cuda for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "982ec985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rocminfo | grep 'Architecture:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74bb780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mROCk module version 6.12.12 is loaded\u001b[0m\n",
      "=====================    \n",
      "HSA System Attributes    \n",
      "=====================    \n",
      "Runtime Version:         1.15\n",
      "Runtime Ext Version:     1.7\n",
      "System Timestamp Freq.:  1000.000000MHz\n",
      "Sig. Max Wait Duration:  18446744073709551615 (0xFFFFFFFFFFFFFFFF) (timestamp count)\n",
      "Machine Model:           LARGE                              \n",
      "System Endianness:       LITTLE                             \n",
      "Mwaitx:                  DISABLED\n",
      "XNACK enabled:           NO\n",
      "DMAbuf Support:          YES\n",
      "VMM Support:             YES\n",
      "\n",
      "==========               \n",
      "HSA Agents               \n",
      "==========               \n",
      "*******                  \n",
      "Agent 1                  \n",
      "*******                  \n",
      "  Name:                    AMD EPYC 7V13 64-Core Processor    \n",
      "  Uuid:                    CPU-XX                             \n",
      "  Marketing Name:          AMD EPYC 7V13 64-Core Processor    \n",
      "  Vendor Name:             CPU                                \n",
      "  Feature:                 None specified                     \n",
      "  Profile:                 FULL_PROFILE                       \n",
      "  Float Round Mode:        NEAR                               \n",
      "  Max Queue Number:        0(0x0)                             \n",
      "  Queue Min Size:          0(0x0)                             \n",
      "  Queue Max Size:          0(0x0)                             \n",
      "  Queue Type:              MULTI                              \n",
      "  Node:                    0                                  \n",
      "  Device Type:             CPU                                \n",
      "  Cache Info:              \n",
      "    L1:                      32768(0x8000) KB                   \n",
      "  Chip ID:                 0(0x0)                             \n",
      "  ASIC Revision:           0(0x0)                             \n",
      "  Cacheline Size:          64(0x40)                           \n",
      "  Max Clock Freq. (MHz):   2450                               \n",
      "  BDFID:                   0                                  \n",
      "  Internal Node ID:        0                                  \n",
      "  Compute Unit:            64                                 \n",
      "  SIMDs per CU:            0                                  \n",
      "  Shader Engines:          0                                  \n",
      "  Shader Arrs. per Eng.:   0                                  \n",
      "  WatchPts on Addr. Ranges:1                                  \n",
      "  Memory Properties:       \n",
      "  Features:                None\n",
      "  Pool Info:               \n",
      "    Pool 1                   \n",
      "      Segment:                 GLOBAL; FLAGS: FINE GRAINED        \n",
      "      Size:                    263477264(0xfb45810) KB            \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:4KB                                \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       TRUE                               \n",
      "    Pool 2                   \n",
      "      Segment:                 GLOBAL; FLAGS: EXTENDED FINE GRAINED\n",
      "      Size:                    263477264(0xfb45810) KB            \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:4KB                                \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       TRUE                               \n",
      "    Pool 3                   \n",
      "      Segment:                 GLOBAL; FLAGS: KERNARG, FINE GRAINED\n",
      "      Size:                    263477264(0xfb45810) KB            \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:4KB                                \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       TRUE                               \n",
      "    Pool 4                   \n",
      "      Segment:                 GLOBAL; FLAGS: COARSE GRAINED      \n",
      "      Size:                    263477264(0xfb45810) KB            \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:4KB                                \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       TRUE                               \n",
      "  ISA Info:                \n",
      "*******                  \n",
      "Agent 2                  \n",
      "*******                  \n",
      "  Name:                    AMD EPYC 7V13 64-Core Processor    \n",
      "  Uuid:                    CPU-XX                             \n",
      "  Marketing Name:          AMD EPYC 7V13 64-Core Processor    \n",
      "  Vendor Name:             CPU                                \n",
      "  Feature:                 None specified                     \n",
      "  Profile:                 FULL_PROFILE                       \n",
      "  Float Round Mode:        NEAR                               \n",
      "  Max Queue Number:        0(0x0)                             \n",
      "  Queue Min Size:          0(0x0)                             \n",
      "  Queue Max Size:          0(0x0)                             \n",
      "  Queue Type:              MULTI                              \n",
      "  Node:                    1                                  \n",
      "  Device Type:             CPU                                \n",
      "  Cache Info:              \n",
      "    L1:                      32768(0x8000) KB                   \n",
      "  Chip ID:                 0(0x0)                             \n",
      "  ASIC Revision:           0(0x0)                             \n",
      "  Cacheline Size:          64(0x40)                           \n",
      "  Max Clock Freq. (MHz):   2450                               \n",
      "  BDFID:                   0                                  \n",
      "  Internal Node ID:        1                                  \n",
      "  Compute Unit:            64                                 \n",
      "  SIMDs per CU:            0                                  \n",
      "  Shader Engines:          0                                  \n",
      "  Shader Arrs. per Eng.:   0                                  \n",
      "  WatchPts on Addr. Ranges:1                                  \n",
      "  Memory Properties:       \n",
      "  Features:                None\n",
      "  Pool Info:               \n",
      "    Pool 1                   \n",
      "      Segment:                 GLOBAL; FLAGS: FINE GRAINED        \n",
      "      Size:                    264172664(0xfbef478) KB            \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:4KB                                \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       TRUE                               \n",
      "    Pool 2                   \n",
      "      Segment:                 GLOBAL; FLAGS: EXTENDED FINE GRAINED\n",
      "      Size:                    264172664(0xfbef478) KB            \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:4KB                                \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       TRUE                               \n",
      "    Pool 3                   \n",
      "      Segment:                 GLOBAL; FLAGS: KERNARG, FINE GRAINED\n",
      "      Size:                    264172664(0xfbef478) KB            \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:4KB                                \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       TRUE                               \n",
      "    Pool 4                   \n",
      "      Segment:                 GLOBAL; FLAGS: COARSE GRAINED      \n",
      "      Size:                    264172664(0xfbef478) KB            \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:4KB                                \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       TRUE                               \n",
      "  ISA Info:                \n",
      "*******                  \n",
      "Agent 3                  \n",
      "*******                  \n",
      "  Name:                    gfx90a                             \n",
      "  Uuid:                    GPU-ca5aa8e116c76c6d               \n",
      "  Marketing Name:          AMD Instinct MI210                 \n",
      "  Vendor Name:             AMD                                \n",
      "  Feature:                 KERNEL_DISPATCH                    \n",
      "  Profile:                 BASE_PROFILE                       \n",
      "  Float Round Mode:        NEAR                               \n",
      "  Max Queue Number:        128(0x80)                          \n",
      "  Queue Min Size:          64(0x40)                           \n",
      "  Queue Max Size:          131072(0x20000)                    \n",
      "  Queue Type:              MULTI                              \n",
      "  Node:                    2                                  \n",
      "  Device Type:             GPU                                \n",
      "  Cache Info:              \n",
      "    L1:                      16(0x10) KB                        \n",
      "    L2:                      8192(0x2000) KB                    \n",
      "  Chip ID:                 29711(0x740f)                      \n",
      "  ASIC Revision:           1(0x1)                             \n",
      "  Cacheline Size:          128(0x80)                          \n",
      "  Max Clock Freq. (MHz):   1700                               \n",
      "  BDFID:                   58112                              \n",
      "  Internal Node ID:        2                                  \n",
      "  Compute Unit:            104                                \n",
      "  SIMDs per CU:            4                                  \n",
      "  Shader Engines:          8                                  \n",
      "  Shader Arrs. per Eng.:   1                                  \n",
      "  WatchPts on Addr. Ranges:4                                  \n",
      "  Coherent Host Access:    FALSE                              \n",
      "  Memory Properties:       \n",
      "  Features:                KERNEL_DISPATCH \n",
      "  Fast F16 Operation:      TRUE                               \n",
      "  Wavefront Size:          64(0x40)                           \n",
      "  Workgroup Max Size:      1024(0x400)                        \n",
      "  Workgroup Max Size per Dimension:\n",
      "    x                        1024(0x400)                        \n",
      "    y                        1024(0x400)                        \n",
      "    z                        1024(0x400)                        \n",
      "  Max Waves Per CU:        32(0x20)                           \n",
      "  Max Work-item Per CU:    2048(0x800)                        \n",
      "  Grid Max Size:           4294967295(0xffffffff)             \n",
      "  Grid Max Size per Dimension:\n",
      "    x                        4294967295(0xffffffff)             \n",
      "    y                        4294967295(0xffffffff)             \n",
      "    z                        4294967295(0xffffffff)             \n",
      "  Max fbarriers/Workgrp:   32                                 \n",
      "  Packet Processor uCode:: 96                                 \n",
      "  SDMA engine uCode::      9                                  \n",
      "  IOMMU Support::          None                               \n",
      "  Pool Info:               \n",
      "    Pool 1                   \n",
      "      Segment:                 GLOBAL; FLAGS: COARSE GRAINED      \n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 2                   \n",
      "      Segment:                 GLOBAL; FLAGS: EXTENDED FINE GRAINED\n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 3                   \n",
      "      Segment:                 GLOBAL; FLAGS: FINE GRAINED        \n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 4                   \n",
      "      Segment:                 GROUP                              \n",
      "      Size:                    64(0x40) KB                        \n",
      "      Allocatable:             FALSE                              \n",
      "      Alloc Granule:           0KB                                \n",
      "      Alloc Recommended Granule:0KB                                \n",
      "      Alloc Alignment:         0KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "  ISA Info:                \n",
      "    ISA 1                    \n",
      "      Name:                    amdgcn-amd-amdhsa--gfx90a:sramecc+:xnack-\n",
      "      Machine Models:          HSA_MACHINE_MODEL_LARGE            \n",
      "      Profiles:                HSA_PROFILE_BASE                   \n",
      "      Default Rounding Mode:   NEAR                               \n",
      "      Default Rounding Mode:   NEAR                               \n",
      "      Fast f16:                TRUE                               \n",
      "      Workgroup Max Size:      1024(0x400)                        \n",
      "      Workgroup Max Size per Dimension:\n",
      "        x                        1024(0x400)                        \n",
      "        y                        1024(0x400)                        \n",
      "        z                        1024(0x400)                        \n",
      "      Grid Max Size:           4294967295(0xffffffff)             \n",
      "      Grid Max Size per Dimension:\n",
      "        x                        4294967295(0xffffffff)             \n",
      "        y                        4294967295(0xffffffff)             \n",
      "        z                        4294967295(0xffffffff)             \n",
      "      FBarrier Max Size:       32                                 \n",
      "*******                  \n",
      "Agent 4                  \n",
      "*******                  \n",
      "  Name:                    gfx90a                             \n",
      "  Uuid:                    GPU-306b6b514c6aece9               \n",
      "  Marketing Name:          AMD Instinct MI210                 \n",
      "  Vendor Name:             AMD                                \n",
      "  Feature:                 KERNEL_DISPATCH                    \n",
      "  Profile:                 BASE_PROFILE                       \n",
      "  Float Round Mode:        NEAR                               \n",
      "  Max Queue Number:        128(0x80)                          \n",
      "  Queue Min Size:          64(0x40)                           \n",
      "  Queue Max Size:          131072(0x20000)                    \n",
      "  Queue Type:              MULTI                              \n",
      "  Node:                    3                                  \n",
      "  Device Type:             GPU                                \n",
      "  Cache Info:              \n",
      "    L1:                      16(0x10) KB                        \n",
      "    L2:                      8192(0x2000) KB                    \n",
      "  Chip ID:                 29711(0x740f)                      \n",
      "  ASIC Revision:           1(0x1)                             \n",
      "  Cacheline Size:          128(0x80)                          \n",
      "  Max Clock Freq. (MHz):   1700                               \n",
      "  BDFID:                   49920                              \n",
      "  Internal Node ID:        3                                  \n",
      "  Compute Unit:            104                                \n",
      "  SIMDs per CU:            4                                  \n",
      "  Shader Engines:          8                                  \n",
      "  Shader Arrs. per Eng.:   1                                  \n",
      "  WatchPts on Addr. Ranges:4                                  \n",
      "  Coherent Host Access:    FALSE                              \n",
      "  Memory Properties:       \n",
      "  Features:                KERNEL_DISPATCH \n",
      "  Fast F16 Operation:      TRUE                               \n",
      "  Wavefront Size:          64(0x40)                           \n",
      "  Workgroup Max Size:      1024(0x400)                        \n",
      "  Workgroup Max Size per Dimension:\n",
      "    x                        1024(0x400)                        \n",
      "    y                        1024(0x400)                        \n",
      "    z                        1024(0x400)                        \n",
      "  Max Waves Per CU:        32(0x20)                           \n",
      "  Max Work-item Per CU:    2048(0x800)                        \n",
      "  Grid Max Size:           4294967295(0xffffffff)             \n",
      "  Grid Max Size per Dimension:\n",
      "    x                        4294967295(0xffffffff)             \n",
      "    y                        4294967295(0xffffffff)             \n",
      "    z                        4294967295(0xffffffff)             \n",
      "  Max fbarriers/Workgrp:   32                                 \n",
      "  Packet Processor uCode:: 96                                 \n",
      "  SDMA engine uCode::      9                                  \n",
      "  IOMMU Support::          None                               \n",
      "  Pool Info:               \n",
      "    Pool 1                   \n",
      "      Segment:                 GLOBAL; FLAGS: COARSE GRAINED      \n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 2                   \n",
      "      Segment:                 GLOBAL; FLAGS: EXTENDED FINE GRAINED\n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 3                   \n",
      "      Segment:                 GLOBAL; FLAGS: FINE GRAINED        \n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 4                   \n",
      "      Segment:                 GROUP                              \n",
      "      Size:                    64(0x40) KB                        \n",
      "      Allocatable:             FALSE                              \n",
      "      Alloc Granule:           0KB                                \n",
      "      Alloc Recommended Granule:0KB                                \n",
      "      Alloc Alignment:         0KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "  ISA Info:                \n",
      "    ISA 1                    \n",
      "      Name:                    amdgcn-amd-amdhsa--gfx90a:sramecc+:xnack-\n",
      "      Machine Models:          HSA_MACHINE_MODEL_LARGE            \n",
      "      Profiles:                HSA_PROFILE_BASE                   \n",
      "      Default Rounding Mode:   NEAR                               \n",
      "      Default Rounding Mode:   NEAR                               \n",
      "      Fast f16:                TRUE                               \n",
      "      Workgroup Max Size:      1024(0x400)                        \n",
      "      Workgroup Max Size per Dimension:\n",
      "        x                        1024(0x400)                        \n",
      "        y                        1024(0x400)                        \n",
      "        z                        1024(0x400)                        \n",
      "      Grid Max Size:           4294967295(0xffffffff)             \n",
      "      Grid Max Size per Dimension:\n",
      "        x                        4294967295(0xffffffff)             \n",
      "        y                        4294967295(0xffffffff)             \n",
      "        z                        4294967295(0xffffffff)             \n",
      "      FBarrier Max Size:       32                                 \n",
      "*******                  \n",
      "Agent 5                  \n",
      "*******                  \n",
      "  Name:                    gfx90a                             \n",
      "  Uuid:                    GPU-4fdc6fe991fe91e4               \n",
      "  Marketing Name:          AMD Instinct MI210                 \n",
      "  Vendor Name:             AMD                                \n",
      "  Feature:                 KERNEL_DISPATCH                    \n",
      "  Profile:                 BASE_PROFILE                       \n",
      "  Float Round Mode:        NEAR                               \n",
      "  Max Queue Number:        128(0x80)                          \n",
      "  Queue Min Size:          64(0x40)                           \n",
      "  Queue Max Size:          131072(0x20000)                    \n",
      "  Queue Type:              MULTI                              \n",
      "  Node:                    4                                  \n",
      "  Device Type:             GPU                                \n",
      "  Cache Info:              \n",
      "    L1:                      16(0x10) KB                        \n",
      "    L2:                      8192(0x2000) KB                    \n",
      "  Chip ID:                 29711(0x740f)                      \n",
      "  ASIC Revision:           1(0x1)                             \n",
      "  Cacheline Size:          128(0x80)                          \n",
      "  Max Clock Freq. (MHz):   1700                               \n",
      "  BDFID:                   41728                              \n",
      "  Internal Node ID:        4                                  \n",
      "  Compute Unit:            104                                \n",
      "  SIMDs per CU:            4                                  \n",
      "  Shader Engines:          8                                  \n",
      "  Shader Arrs. per Eng.:   1                                  \n",
      "  WatchPts on Addr. Ranges:4                                  \n",
      "  Coherent Host Access:    FALSE                              \n",
      "  Memory Properties:       \n",
      "  Features:                KERNEL_DISPATCH \n",
      "  Fast F16 Operation:      TRUE                               \n",
      "  Wavefront Size:          64(0x40)                           \n",
      "  Workgroup Max Size:      1024(0x400)                        \n",
      "  Workgroup Max Size per Dimension:\n",
      "    x                        1024(0x400)                        \n",
      "    y                        1024(0x400)                        \n",
      "    z                        1024(0x400)                        \n",
      "  Max Waves Per CU:        32(0x20)                           \n",
      "  Max Work-item Per CU:    2048(0x800)                        \n",
      "  Grid Max Size:           4294967295(0xffffffff)             \n",
      "  Grid Max Size per Dimension:\n",
      "    x                        4294967295(0xffffffff)             \n",
      "    y                        4294967295(0xffffffff)             \n",
      "    z                        4294967295(0xffffffff)             \n",
      "  Max fbarriers/Workgrp:   32                                 \n",
      "  Packet Processor uCode:: 96                                 \n",
      "  SDMA engine uCode::      9                                  \n",
      "  IOMMU Support::          None                               \n",
      "  Pool Info:               \n",
      "    Pool 1                   \n",
      "      Segment:                 GLOBAL; FLAGS: COARSE GRAINED      \n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 2                   \n",
      "      Segment:                 GLOBAL; FLAGS: EXTENDED FINE GRAINED\n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 3                   \n",
      "      Segment:                 GLOBAL; FLAGS: FINE GRAINED        \n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 4                   \n",
      "      Segment:                 GROUP                              \n",
      "      Size:                    64(0x40) KB                        \n",
      "      Allocatable:             FALSE                              \n",
      "      Alloc Granule:           0KB                                \n",
      "      Alloc Recommended Granule:0KB                                \n",
      "      Alloc Alignment:         0KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "  ISA Info:                \n",
      "    ISA 1                    \n",
      "      Name:                    amdgcn-amd-amdhsa--gfx90a:sramecc+:xnack-\n",
      "      Machine Models:          HSA_MACHINE_MODEL_LARGE            \n",
      "      Profiles:                HSA_PROFILE_BASE                   \n",
      "      Default Rounding Mode:   NEAR                               \n",
      "      Default Rounding Mode:   NEAR                               \n",
      "      Fast f16:                TRUE                               \n",
      "      Workgroup Max Size:      1024(0x400)                        \n",
      "      Workgroup Max Size per Dimension:\n",
      "        x                        1024(0x400)                        \n",
      "        y                        1024(0x400)                        \n",
      "        z                        1024(0x400)                        \n",
      "      Grid Max Size:           4294967295(0xffffffff)             \n",
      "      Grid Max Size per Dimension:\n",
      "        x                        4294967295(0xffffffff)             \n",
      "        y                        4294967295(0xffffffff)             \n",
      "        z                        4294967295(0xffffffff)             \n",
      "      FBarrier Max Size:       32                                 \n",
      "*******                  \n",
      "Agent 6                  \n",
      "*******                  \n",
      "  Name:                    gfx90a                             \n",
      "  Uuid:                    GPU-f6f3f279c7862e39               \n",
      "  Marketing Name:          AMD Instinct MI210                 \n",
      "  Vendor Name:             AMD                                \n",
      "  Feature:                 KERNEL_DISPATCH                    \n",
      "  Profile:                 BASE_PROFILE                       \n",
      "  Float Round Mode:        NEAR                               \n",
      "  Max Queue Number:        128(0x80)                          \n",
      "  Queue Min Size:          64(0x40)                           \n",
      "  Queue Max Size:          131072(0x20000)                    \n",
      "  Queue Type:              MULTI                              \n",
      "  Node:                    5                                  \n",
      "  Device Type:             GPU                                \n",
      "  Cache Info:              \n",
      "    L1:                      16(0x10) KB                        \n",
      "    L2:                      8192(0x2000) KB                    \n",
      "  Chip ID:                 29711(0x740f)                      \n",
      "  ASIC Revision:           1(0x1)                             \n",
      "  Cacheline Size:          128(0x80)                          \n",
      "  Max Clock Freq. (MHz):   1700                               \n",
      "  BDFID:                   33536                              \n",
      "  Internal Node ID:        5                                  \n",
      "  Compute Unit:            104                                \n",
      "  SIMDs per CU:            4                                  \n",
      "  Shader Engines:          8                                  \n",
      "  Shader Arrs. per Eng.:   1                                  \n",
      "  WatchPts on Addr. Ranges:4                                  \n",
      "  Coherent Host Access:    FALSE                              \n",
      "  Memory Properties:       \n",
      "  Features:                KERNEL_DISPATCH \n",
      "  Fast F16 Operation:      TRUE                               \n",
      "  Wavefront Size:          64(0x40)                           \n",
      "  Workgroup Max Size:      1024(0x400)                        \n",
      "  Workgroup Max Size per Dimension:\n",
      "    x                        1024(0x400)                        \n",
      "    y                        1024(0x400)                        \n",
      "    z                        1024(0x400)                        \n",
      "  Max Waves Per CU:        32(0x20)                           \n",
      "  Max Work-item Per CU:    2048(0x800)                        \n",
      "  Grid Max Size:           4294967295(0xffffffff)             \n",
      "  Grid Max Size per Dimension:\n",
      "    x                        4294967295(0xffffffff)             \n",
      "    y                        4294967295(0xffffffff)             \n",
      "    z                        4294967295(0xffffffff)             \n",
      "  Max fbarriers/Workgrp:   32                                 \n",
      "  Packet Processor uCode:: 96                                 \n",
      "  SDMA engine uCode::      9                                  \n",
      "  IOMMU Support::          None                               \n",
      "  Pool Info:               \n",
      "    Pool 1                   \n",
      "      Segment:                 GLOBAL; FLAGS: COARSE GRAINED      \n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 2                   \n",
      "      Segment:                 GLOBAL; FLAGS: EXTENDED FINE GRAINED\n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 3                   \n",
      "      Segment:                 GLOBAL; FLAGS: FINE GRAINED        \n",
      "      Size:                    67092480(0x3ffc000) KB             \n",
      "      Allocatable:             TRUE                               \n",
      "      Alloc Granule:           4KB                                \n",
      "      Alloc Recommended Granule:2048KB                             \n",
      "      Alloc Alignment:         4KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "    Pool 4                   \n",
      "      Segment:                 GROUP                              \n",
      "      Size:                    64(0x40) KB                        \n",
      "      Allocatable:             FALSE                              \n",
      "      Alloc Granule:           0KB                                \n",
      "      Alloc Recommended Granule:0KB                                \n",
      "      Alloc Alignment:         0KB                                \n",
      "      Accessible by all:       FALSE                              \n",
      "  ISA Info:                \n",
      "    ISA 1                    \n",
      "      Name:                    amdgcn-amd-amdhsa--gfx90a:sramecc+:xnack-\n",
      "      Machine Models:          HSA_MACHINE_MODEL_LARGE            \n",
      "      Profiles:                HSA_PROFILE_BASE                   \n",
      "      Default Rounding Mode:   NEAR                               \n",
      "      Default Rounding Mode:   NEAR                               \n",
      "      Fast f16:                TRUE                               \n",
      "      Workgroup Max Size:      1024(0x400)                        \n",
      "      Workgroup Max Size per Dimension:\n",
      "        x                        1024(0x400)                        \n",
      "        y                        1024(0x400)                        \n",
      "        z                        1024(0x400)                        \n",
      "      Grid Max Size:           4294967295(0xffffffff)             \n",
      "      Grid Max Size per Dimension:\n",
      "        x                        4294967295(0xffffffff)             \n",
      "        y                        4294967295(0xffffffff)             \n",
      "        z                        4294967295(0xffffffff)             \n",
      "      FBarrier Max Size:       32                                 \n",
      "*** Done ***             \n"
     ]
    }
   ],
   "source": [
    "!rocminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "617d39d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='903' max='500000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   903/500000 09:01 < 83:18:06, 1.66 it/s, Epoch 0.02/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.752700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/transformers/trainer.py:2328\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2326\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/transformers/trainer.py:2623\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2621\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2622\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2623\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;66;03m# Store the number of batches for current gradient accumulation\u001b[39;00m\n\u001b[1;32m   2625\u001b[0m \u001b[38;5;66;03m# This is used to correctly scale the loss when the last accumulation step has fewer batches\u001b[39;00m\n\u001b[1;32m   2626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_gradient_accumulation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples)\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/transformers/trainer.py:5581\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5580\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5581\u001b[0m         batch_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   5582\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5583\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/data_loader.py:579\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_blocking)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[0;32m--> 579\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    738\u001b[0m ):\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:788\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    787\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 788\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    790\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/transformers/data/data_collator.py:46\u001b[0m, in \u001b[0;36mDataCollatorMixin.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_call(features)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_call(features)\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/transformers/data/data_collator.py:1025\u001b[0m, in \u001b[0;36mDataCollatorForLanguageModeling.torch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m   1023\u001b[0m special_tokens_mask \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecial_tokens_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlm:\n\u001b[0;32m-> 1025\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_mask_tokens\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecial_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspecial_tokens_mask\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1029\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/transformers/data/data_collator.py:1045\u001b[0m, in \u001b[0;36mDataCollatorForLanguageModeling.torch_mask_tokens\u001b[0;34m(self, inputs, special_tokens_mask)\u001b[0m\n\u001b[1;32m   1043\u001b[0m probability_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull(labels\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlm_probability)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m special_tokens_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1045\u001b[0m     special_tokens_mask \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1046\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mget_special_tokens_mask(val, already_has_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m   1047\u001b[0m     ]\n\u001b[1;32m   1048\u001b[0m     special_tokens_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(special_tokens_mask, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/transformers/data/data_collator.py:1046\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1043\u001b[0m probability_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull(labels\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlm_probability)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m special_tokens_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     special_tokens_mask \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 1046\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_special_tokens_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malready_has_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m   1047\u001b[0m     ]\n\u001b[1;32m   1048\u001b[0m     special_tokens_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(special_tokens_mask, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/transformers/tokenization_utils_base.py:3940\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.get_special_tokens_mask\u001b[0;34m(self, token_ids_0, token_ids_1, already_has_special_tokens)\u001b[0m\n\u001b[1;32m   3931\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m already_has_special_tokens \u001b[38;5;129;01mand\u001b[39;00m token_ids_1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (\n\u001b[1;32m   3932\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot use ``already_has_special_tokens=False`` with this tokenizer. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3933\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use a slow (full python) tokenizer to activate this argument. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3934\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOr set `return_special_tokens_mask=True` when calling the encoding method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3935\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get the special tokens mask in any tokenizer. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3936\u001b[0m )\n\u001b[1;32m   3938\u001b[0m all_special_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_special_ids  \u001b[38;5;66;03m# cache the property\u001b[39;00m\n\u001b[0;32m-> 3940\u001b[0m special_tokens_mask \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m all_special_ids \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m token_ids_0]\n\u001b[1;32m   3942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m special_tokens_mask\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/transformers/tokenization_utils_base.py:3940\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3931\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m already_has_special_tokens \u001b[38;5;129;01mand\u001b[39;00m token_ids_1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (\n\u001b[1;32m   3932\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot use ``already_has_special_tokens=False`` with this tokenizer. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3933\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use a slow (full python) tokenizer to activate this argument. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3934\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOr set `return_special_tokens_mask=True` when calling the encoding method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3935\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get the special tokens mask in any tokenizer. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3936\u001b[0m )\n\u001b[1;32m   3938\u001b[0m all_special_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_special_ids  \u001b[38;5;66;03m# cache the property\u001b[39;00m\n\u001b[0;32m-> 3940\u001b[0m special_tokens_mask \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m all_special_ids \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m token_ids_0]\n\u001b[1;32m   3942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m special_tokens_mask\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1cdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/rocm-6.1.2/lib/llvm/bin/ld.lld\n",
      "/opt/rocm-6.2.1/lib/llvm/bin/ld.lld\n",
      "/opt/rocm-6.3.1/lib/llvm/bin/ld.lld\n",
      "/opt/rocm-6.4.1/lib/llvm/bin/ld.lld\n"
     ]
    }
   ],
   "source": [
    "!find /opt/rocm* -name ld.lld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "accelerate                1.2.1\n",
      "aiohappyeyeballs          2.6.1\n",
      "aiohttp                   3.11.14\n",
      "aiosignal                 1.3.2\n",
      "anyio                     4.9.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 3.0.0\n",
      "async-lru                 2.0.5\n",
      "async-timeout             5.0.1\n",
      "attrs                     25.3.0\n",
      "babel                     2.17.0\n",
      "beautifulsoup4            4.13.3\n",
      "bleach                    6.2.0\n",
      "certifi                   2025.1.31\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.4.1\n",
      "click                     8.1.8\n",
      "comm                      0.2.2\n",
      "datasets                  3.2.0\n",
      "debugpy                   1.8.13\n",
      "decorator                 5.2.1\n",
      "defusedxml                0.7.1\n",
      "dill                      0.3.8\n",
      "einops                    0.8.1\n",
      "evaluate                  0.4.3\n",
      "exceptiongroup            1.2.2\n",
      "executing                 2.2.0\n",
      "fastjsonschema            2.21.1\n",
      "filelock                  3.13.1\n",
      "flash_attn                2.7.4.post1\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.5.0\n",
      "fsspec                    2024.6.1\n",
      "ftfy                      6.3.1\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.7\n",
      "httpx                     0.28.1\n",
      "huggingface-hub           0.29.3\n",
      "idna                      3.10\n",
      "importlib_metadata        8.6.1\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.18.1\n",
      "ipywidgets                8.1.5\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.4\n",
      "joblib                    1.4.2\n",
      "json5                     0.10.0\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter                   1.0.0\n",
      "jupyter_client            8.6.3\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.12.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.15.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.3.6\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.13\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib-inline         0.1.7\n",
      "mistune                   3.1.3\n",
      "mpmath                    1.3.0\n",
      "multidict                 6.2.0\n",
      "multiprocess              0.70.16\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.6\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.2.1\n",
      "ninja                     1.11.1.4\n",
      "nltk                      3.9.1\n",
      "notebook                  7.3.3\n",
      "notebook_shim             0.2.4\n",
      "numpy                     1.26.3\n",
      "overrides                 7.7.0\n",
      "packaging                 24.2\n",
      "pandas                    2.2.3\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pexpect                   4.9.0\n",
      "pillow                    11.0.0\n",
      "pip                       25.2\n",
      "platformdirs              4.3.7\n",
      "prometheus_client         0.21.1\n",
      "prompt_toolkit            3.0.50\n",
      "propcache                 0.3.1\n",
      "psutil                    7.0.0\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "pyarrow                   19.0.1\n",
      "pycparser                 2.22\n",
      "Pygments                  2.19.1\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        3.3.0\n",
      "pytorch-triton-rocm       3.1.0\n",
      "pytz                      2025.2\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.3.0\n",
      "qtconsole                 5.6.1\n",
      "QtPy                      2.4.3\n",
      "referencing               0.36.2\n",
      "regex                     2024.11.6\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.24.0\n",
      "safetensors               0.5.3\n",
      "scikit-learn              1.5.2\n",
      "scipy                     1.13.1\n",
      "Send2Trash                1.8.3\n",
      "seqeval                   1.2.2\n",
      "setuptools                80.9.0\n",
      "six                       1.17.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.6\n",
      "stack-data                0.6.3\n",
      "sympy                     1.13.1\n",
      "terminado                 0.18.1\n",
      "threadpoolctl             3.6.0\n",
      "tinycss2                  1.4.0\n",
      "tokenizers                0.21.1\n",
      "tomli                     2.2.1\n",
      "torch                     2.5.1+rocm6.2\n",
      "torchaudio                2.5.1+rocm6.2\n",
      "torchvision               0.20.1+rocm6.2\n",
      "tornado                   6.4.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "transformers              4.48.1\n",
      "triton                    3.4.0\n",
      "types-python-dateutil     2.9.0.20241206\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2025.2\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.3.0\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.11.1\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "wheel                     0.45.1\n",
      "widgetsnbextension        4.0.13\n",
      "xxhash                    3.5.0\n",
      "yarl                      1.18.3\n",
      "zipp                      3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# All necessary imports\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "\n",
    "# ====================================================================\n",
    "# STEP 1: Define your training logic inside a single function\n",
    "# ====================================================================\n",
    "def training_function():\n",
    "    # Initialize the Accelerator\n",
    "    # It automatically handles device placement (e.g., 'cuda:0', 'cuda:1')\n",
    "    accelerator = Accelerator()\n",
    "    \n",
    "    # --- Create your model, optimizer, and dataloaders ---\n",
    "    # (It's important to create them here, inside the function)\n",
    "    model = torch.nn.Linear(50, 10)\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "    # Create some dummy data\n",
    "    X = torch.randn(2048, 50)\n",
    "    y = torch.randint(0, 10, (2048,))\n",
    "    dataset = TensorDataset(X, y)\n",
    "    # The dataloader will be automatically sharded across GPUs by accelerator.prepare()\n",
    "    dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "    # --- Use accelerator.prepare() ---\n",
    "    # This is the magic step! It wraps your objects to work in a distributed environment.\n",
    "    model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)\n",
    "    \n",
    "    # --- Your Training Loop ---\n",
    "    model.train()\n",
    "    for epoch in range(3):\n",
    "        for batch in dataloader:\n",
    "            inputs, targets = batch\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, targets)\n",
    "            \n",
    "            # Backward pass - use accelerator.backward() instead of loss.backward()\n",
    "            accelerator.backward(loss)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        # Use accelerator.print to avoid printing from every process\n",
    "        accelerator.print(f\"Epoch {epoch} | Loss: {loss.item()}\")\n",
    "\n",
    "# ====================================================================\n",
    "# STEP 2: Launch the training function with notebook_launcher\n",
    "# ====================================================================\n",
    "# %%\n",
    "# This will launch `training_function` on 2 GPUs.\n",
    "# The code in this cell will wait until the training is complete.\n",
    "notebook_launcher(training_function, num_processes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5d7e5",
   "metadata": {},
   "source": [
    "## Trying using accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28743685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933bddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 4 CUDAs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "W0926 20:25:40.393144 1572853 torch/multiprocessing/spawn.py:175] Terminating process 1572941 via signal SIGTERM\n",
      "W0926 20:25:40.394976 1572853 torch/multiprocessing/spawn.py:175] Terminating process 1572942 via signal SIGTERM\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742] failed (exitcode: 1) local_rank: 0 (pid: 1572939) of fn: run_training (start_method: fork)\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742] Traceback (most recent call last):\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 697, in _poll\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     self._pc.join(-1)\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 221, in join\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742] torch.multiprocessing.spawn.ProcessRaisedException: \n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742] \n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742] -- Process 0 terminated with the following error:\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742] Traceback (most recent call last):\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 96, in _wrap\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     fn(i, *args)\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 617, in _wrap\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     ret = record(fn)(*args_)\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 357, in wrapper\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     return f(*args, **kwargs)\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/tmp/ipykernel_1572853/2636644470.py\", line 17, in run_training\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     accelerator = Accelerator()\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/accelerator.py\", line 462, in __init__\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     self.state = AcceleratorState(\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/state.py\", line 912, in __init__\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     PartialState(cpu, **kwargs)\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/state.py\", line 301, in __init__\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     self.set_device()\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/state.py\", line 838, in set_device\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     device_module.set_device(self.device)\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/cuda/__init__.py\", line 567, in set_device\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     torch._C._cuda_setDevice(device)\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]   File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/cuda/__init__.py\", line 398, in _lazy_init\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742]     raise RuntimeError(\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742] RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
      "E0926 20:25:40.482525 1572853 torch/distributed/elastic/multiprocessing/api.py:742] \n"
     ]
    },
    {
     "ename": "ChildFailedError",
     "evalue": "\n============================================================\nrun_training FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2025-09-26_20:25:40\n  host      : k005-009.hpcfund\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 1572939)\n  error_file: /tmp/torchelastic_p_45ufg5/none__3lvwe1u/attempt_0/0/error.json\n  traceback : Traceback (most recent call last):\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 357, in wrapper\n      return f(*args, **kwargs)\n    File \"/tmp/ipykernel_1572853/2636644470.py\", line 17, in run_training\n      accelerator = Accelerator()\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/accelerator.py\", line 462, in __init__\n      self.state = AcceleratorState(\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/state.py\", line 912, in __init__\n      PartialState(cpu, **kwargs)\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/state.py\", line 301, in __init__\n      self.set_device()\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/state.py\", line 838, in set_device\n      device_module.set_device(self.device)\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/cuda/__init__.py\", line 567, in set_device\n      torch._C._cuda_setDevice(device)\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/cuda/__init__.py\", line 398, in _lazy_init\n      raise RuntimeError(\n  RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n  \n============================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mChildFailedError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m notebook_launcher\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This will launch the function you defined above on 4 GPUs.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# The notebook will wait here until the training is finished.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_training\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/launchers.py:247\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes, rdzv_backend, rdzv_endpoint, rdzv_conf, rdzv_id, max_restarts, monitor_interval, log_line_prefix_template)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;124m\"\u001b[39m, ELASTIC_LOG_LINE_PREFIX_TEMPLATE_PYTORCH_VERSION):\n\u001b[1;32m    246\u001b[0m         launch_config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_line_prefix_template\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_line_prefix_template\n\u001b[0;32m--> 247\u001b[0m     \u001b[43melastic_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLaunchConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlaunch_config_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_type\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in forked subprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/distributed/launcher/api.py:162\u001b[0m, in \u001b[0;36melastic_launch.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlaunch_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_entrypoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/distributed/launcher/api.py:299\u001b[0m, in \u001b[0;36mlaunch_agent\u001b[0;34m(config, entrypoint, args)\u001b[0m\n\u001b[1;32m    292\u001b[0m     events\u001b[38;5;241m.\u001b[39mrecord(agent\u001b[38;5;241m.\u001b[39mget_event_succeeded(), config\u001b[38;5;241m.\u001b[39mevent_log_handler)\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mis_failed():\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;66;03m# ChildFailedError is treated specially by @record\u001b[39;00m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;66;03m# if the error files for the failed children exist\u001b[39;00m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# @record will copy the first error (root cause)\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;66;03m# to the error file of the launcher process.\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChildFailedError(\n\u001b[1;32m    300\u001b[0m             name\u001b[38;5;241m=\u001b[39mentrypoint_name,\n\u001b[1;32m    301\u001b[0m             failures\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mfailures,\n\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturn_values\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ChildFailedError:\n",
      "\u001b[0;31mChildFailedError\u001b[0m: \n============================================================\nrun_training FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2025-09-26_20:25:40\n  host      : k005-009.hpcfund\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 1572939)\n  error_file: /tmp/torchelastic_p_45ufg5/none__3lvwe1u/attempt_0/0/error.json\n  traceback : Traceback (most recent call last):\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 357, in wrapper\n      return f(*args, **kwargs)\n    File \"/tmp/ipykernel_1572853/2636644470.py\", line 17, in run_training\n      accelerator = Accelerator()\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/accelerator.py\", line 462, in __init__\n      self.state = AcceleratorState(\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/state.py\", line 912, in __init__\n      PartialState(cpu, **kwargs)\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/state.py\", line 301, in __init__\n      self.set_device()\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/accelerate/state.py\", line 838, in set_device\n      device_module.set_device(self.device)\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/cuda/__init__.py\", line 567, in set_device\n      torch._C._cuda_setDevice(device)\n    File \"/work1/lgarcia/renneruan/amd_200/lib64/python3.9/site-packages/torch/cuda/__init__.py\", line 398, in _lazy_init\n      raise RuntimeError(\n  RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n  \n============================================================"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amd_200",
   "language": "python",
   "name": "amd_200"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
